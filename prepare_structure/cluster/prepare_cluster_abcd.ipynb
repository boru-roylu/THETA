{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 18:15:34.555549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-04 18:15:34.808975: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-04 18:15:36.326340: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-04 18:15:36.326455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-04 18:15:36.326461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "\n",
    "import gc\n",
    "\n",
    "import copy\n",
    "import datasets\n",
    "import decouple\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers as tfs\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "import analyze_utils\n",
    "import clustering_utils\n",
    "import data_collator\n",
    "import modeling_bert\n",
    "import utils\n",
    "\n",
    "SCRATCH_DIR = decouple.config('SCRATCH_PARENT_DIR')\n",
    "NFS_DIR = decouple.config('NFS_PARENT_DIR')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads data and initialize paths.\n",
    "### Uses the corresponding script to create data first. (see file in data_sripts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusts batch size according to your GPU size.\n",
    "batch_size = 48\n",
    "cuda_device = 0\n",
    "data_name = 'abcd'\n",
    "debug_mode = False\n",
    "\n",
    "task_name = 'pretrain'\n",
    "pos_type = 'absolute'\n",
    "\n",
    "model_name = 'hibert'\n",
    "data_config_path = f'../../config/data/{data_name}.yaml'\n",
    "coordinator_config_path = f'../../config/model/theta-cls-hibert/cls-hibert-absolute-pos-config-1layer-2head.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = utils.read_yaml(data_config_path)\n",
    "\n",
    "pop_keys = ['mlm_labels', 'labels', 'sentence_masked_idxs']\n",
    "model_path = data_config['path']['dapt_model_path'].format(nfs_dir=NFS_DIR)\n",
    "\n",
    "assert os.path.isdir(model_path), model_path\n",
    "emb_dir = data_config['path']['embedding_dir'].format(nfs_dir=NFS_DIR)\n",
    "assignment_dir = data_config['path']['assignment_dir'].format(nfs_dir=NFS_DIR)\n",
    "\n",
    "coordinator_config = tfs.AutoConfig.from_pretrained(coordinator_config_path)\n",
    "\n",
    "os.makedirs(emb_dir, exist_ok=True)\n",
    "os.makedirs(assignment_dir, exist_ok=True)\n",
    "\n",
    "print(f'{model_path = }')\n",
    "print(f'{coordinator_config_path = }')\n",
    "print(f'{emb_dir = }')\n",
    "print(f'{assignment_dir = }')\n",
    "\n",
    "tokenizer = tfs.AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model_config = tfs.AutoConfig.from_pretrained(model_path)\n",
    "\n",
    "dataset_dir = data_config['path']['dataset_dir'].format(scratch_dir=SCRATCH_DIR)\n",
    "\n",
    "local_ds_dir = \\\n",
    "    utils.get_dataset_dir_map(task_name, dataset_dir, model_path, debug_mode)\n",
    "\n",
    "raw_ds = datasets.DatasetDict.load_from_disk(local_ds_dir['raw_ds'])\n",
    "ds = copy.deepcopy(raw_ds)\n",
    "ds.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shows an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "for turn in raw_ds['train']['dialogue'][idx]:\n",
    "    utt = turn['turn']\n",
    "    party = turn['party']\n",
    "    print(f'{party:>10}: {utt}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads the model and extract embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modeling_bert.HierarchicalBertModel(\n",
    "    config=model_config, coordinator_config=coordinator_config)\n",
    "model.bert = tfs.AutoModel.from_pretrained(model_path)\n",
    "\n",
    "_ = model.cuda(cuda_device)\n",
    "_ = model.eval()\n",
    "\n",
    "dc = data_collator.DataCollatorForWholeWordMaskAndWholeSentenceMask(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm_probability=0.0,\n",
    "    msm_probability=0.0,\n",
    "    max_num_turns=data_config['config']['max_num_turns'],\n",
    "    min_num_valid_tokens=0,\n",
    "    mask_whole_sentence=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracts embeddings. (You can skip the step if you already did it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_to_output = {}\n",
    "for split in data_config['config']['splits']:\n",
    "    print(f'Processing {split} set.')\n",
    "    output = clustering_utils.get_turn_embeddings(\n",
    "        model, ds[split], dc, batch_size, pop_keys, cuda_device)\n",
    "    analyze_utils.save_embeddings(\n",
    "        emb_dir, split, output, embedding_names=['bert_mean_pooler_output'])\n",
    "    split_to_output[split] = output\n",
    "\n",
    "# Cleans model on the GPU before using GPU-based clustering.\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads extraced embeddings.\n",
    "If you already extracted embeddings, you can skip the process of extracting \n",
    "embeddings above and directly load embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_to_output = {}\n",
    "for split in data_config['config']['splits']:\n",
    "    split_to_output[split] = analyze_utils.load_embeddings(emb_dir, split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters turn embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABCD\n",
    "# Sets the num of clusters.\n",
    "num_clusters = 60\n",
    "\n",
    "# Sets how many turns for each cluster you want to keep.\n",
    "topk_center_turns = 20\n",
    "\n",
    "dialog_act_to_full_name = {}\n",
    "speaker1 = 'customer'\n",
    "speaker2 = 'agent'\n",
    "da_col = None\n",
    "dialog_act_to_idx = None\n",
    "string_match_dialog_act_set = None\n",
    "embedding_names = ['bert_mean_pooler_output']\n",
    "\n",
    "\n",
    "# Gets speaker indices.\n",
    "split_to_df = {}\n",
    "# Clusters two parties independently.\n",
    "split_to_speaker1_idxs = {}\n",
    "split_to_speaker2_idxs = {}\n",
    "for split in data_config['config']['splits']:\n",
    "    df = analyze_utils.get_label_dataframe(\n",
    "        raw_ds[split], dialog_act_to_idx, da_col)\n",
    "    df = df[df['party'] != '<start>']\n",
    "    speaker1_idxs, speaker2_idxs = clustering_utils.get_idxs_for_clustering(\n",
    "        df, speaker1, speaker2, string_match_dialog_act_set)\n",
    "    split_to_df[split] = df\n",
    "    split_to_speaker1_idxs[split] = speaker1_idxs\n",
    "    split_to_speaker2_idxs[split] = speaker2_idxs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "max_num_turns = data_config['config']['max_num_turns']\n",
    "\n",
    "# Shifts cluster if string matching is applied.\n",
    "# Makes sure the string matching clustering uses the index starting from 0.\n",
    "if string_match_dialog_act_set:\n",
    "    kmeans_num_clusters = num_clusters - len(string_match_dialog_act_set)\n",
    "else:\n",
    "    kmeans_num_clusters = num_clusters\n",
    "\n",
    "# Shifts cluster indices for the 2nd party.\n",
    "assignment_idx_offset = num_clusters\n",
    "\n",
    "for embedding_name in tqdm.tqdm(embedding_names):\n",
    "    speaker1_embeddings = {\n",
    "        split: split_to_output[split][embedding_name][split_to_speaker1_idxs[split]]\n",
    "        for split in data_config['config']['splits']\n",
    "    }\n",
    "    speaker2_embeddings = {\n",
    "        split: split_to_output[split][embedding_name][split_to_speaker2_idxs[split]]\n",
    "        for split in data_config['config']['splits']\n",
    "    }\n",
    "\n",
    "    speaker1_distances, speaker1_assignments = clustering_utils.clustering(\n",
    "        data_config['config']['splits'],\n",
    "        speaker1_embeddings,\n",
    "        kmeans_num_clusters,\n",
    "        cuda_device)\n",
    "    speaker2_distances, speaker2_assignments = clustering_utils.clustering(\n",
    "        data_config['config']['splits'],\n",
    "        speaker2_embeddings,\n",
    "        kmeans_num_clusters,\n",
    "        cuda_device)\n",
    "\n",
    "    # Aligns with ground-truth if applicable.\n",
    "    if da_col:\n",
    "        ref_df = copy.deepcopy(split_to_df['dev'])\n",
    "        ref_subdf = ref_df.loc[split_to_speaker1_idxs['dev']]\n",
    "        clustering_utils.align_assignment(speaker1_assignments, ref_subdf)\n",
    "        ref_subdf = ref_df.loc[split_to_speaker2_idxs['dev']]\n",
    "        clustering_utils.align_assignment(speaker2_assignments, ref_subdf)\n",
    "\n",
    "    sub_dir = os.path.join(\n",
    "        assignment_dir, f'{embedding_name}/num_clusters_{num_clusters}')\n",
    "    os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "    for split in data_config['config']['splits']:\n",
    "        df = split_to_df[split]\n",
    "        df2 = copy.deepcopy(df)\n",
    "\n",
    "        if da_col:\n",
    "            # For string-matching DAs, we directly use ground-truth DA indices.\n",
    "            df2['assignment'] = df2['dialog_act_idx']\n",
    "        # For string-matching DAs, distance is 0. \n",
    "        df2['distance'] = [0] * len(df2)\n",
    "\n",
    "        speaker1_idxs = split_to_speaker1_idxs[split]\n",
    "        df2.loc[speaker1_idxs, 'assignment'] = speaker1_assignments[split]\n",
    "        df2.loc[speaker1_idxs, 'distance'] = speaker1_distances[split]\n",
    "\n",
    "        speaker2_idxs = split_to_speaker2_idxs[split]\n",
    "        df2.loc[speaker2_idxs, 'assignment'] = speaker2_assignments[split] \n",
    "        df2.loc[speaker2_idxs, 'distance'] = speaker2_distances[split]\n",
    "\n",
    "        all_speaker2_idxs = df2[df2['party'] == speaker2].index\n",
    "        df2.loc[all_speaker2_idxs, 'assignment'] += assignment_idx_offset\n",
    "        df2['assignment'] = df2['assignment'].astype(int)\n",
    "        path = os.path.join(sub_dir, f'{split}.csv')\n",
    "        df2[['dialog_idx', 'turn_idx', 'assignment']].to_csv(path, index=False)\n",
    "\n",
    "        center_df = df2.groupby('assignment', group_keys=False).apply(\n",
    "                lambda x: x.nsmallest(n=topk_center_turns, columns='distance'))\n",
    "\n",
    "        assignment_to_centers = {}\n",
    "        for assignment, g in center_df.groupby('assignment'):\n",
    "            neighbors = []\n",
    "            for _, row in g.iterrows():\n",
    "                if assignment // num_clusters == 0:\n",
    "                    party = speaker1\n",
    "                else:\n",
    "                    party = speaker2\n",
    "                neighbor = {'party': party, 'turn': row['turn']}\n",
    "                if da_col:\n",
    "                    neighbor['dialog_act'] = row['dialog_act'],\n",
    "                neighbors.append(neighbor)\n",
    "            assignment_to_centers[assignment] = neighbors\n",
    "        \n",
    "        center_path = os.path.join(sub_dir, f'{split}_center.json')\n",
    "        print(f'{\"Save turns nearby centers\":>30} {center_path:<50}')\n",
    "        with open(center_path, 'w') as f:\n",
    "            json.dump(assignment_to_centers, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Oct 12 2021, 13:49:34) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d894f953985df1b1fa232bf092ab4758eff604d12535f541d8fc07db67b454f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
